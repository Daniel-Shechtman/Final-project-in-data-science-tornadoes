{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bc807332",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt      \n",
    "import math\n",
    "\n",
    "import sklearn\n",
    "from sklearn import linear_model, metrics, preprocessing\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecd5b44a",
   "metadata": {},
   "source": [
    "## In the code below we create a new driver (of Selenium) and with its help we obtain information about all the names of the states in the United States."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "36ea07e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-4-683e19ef70c4>:5: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Chrome(options = options, executable_path=DRIVER_PATH)\n",
      "<ipython-input-4-683e19ef70c4>:9: DeprecationWarning: find_elements_by_* commands are deprecated. Please use find_elements() instead\n",
      "  statesElements = driver.find_elements_by_xpath(\"//*[@id='tornadoState']/option\")\n"
     ]
    }
   ],
   "source": [
    "options = Options()\n",
    "options.add_argument(\"--window-size=1920,1200\")\n",
    "\n",
    "DRIVER_PATH = './chromedriver.exe'\n",
    "driver = webdriver.Chrome(options = options, executable_path=DRIVER_PATH)\n",
    "States = []\n",
    "homePageURL = \"https://data.elpasotimes.com/tornado-archive/\"\n",
    "driver.get(homePageURL)\n",
    "statesElements = driver.find_elements_by_xpath(\"//*[@id='tornadoState']/option\")\n",
    "for stateElement in statesElements:\n",
    "    States.append(stateElement.get_attribute(\"value\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5501ccb7",
   "metadata": {},
   "source": [
    "## In the code below we use selenium to get all the hurricanes from each state in the years when there were hurricanes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d0c71fc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-51-59ba9aa89532>:15: DeprecationWarning: find_elements_by_* commands are deprecated. Please use find_elements() instead\n",
      "  yearss = driver.find_elements_by_xpath('//*[@id=\"tornadoSummary\"]/tbody/tr')\n",
      "C:\\Users\\dsisb\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webelement.py:393: UserWarning: find_element_by_* commands are deprecated. Please use find_element() instead\n",
      "  warnings.warn(\"find_element_by_* commands are deprecated. Please use find_element() instead\")\n",
      "<ipython-input-51-59ba9aa89532>:22: DeprecationWarning: find_elements_by_* commands are deprecated. Please use find_elements() instead\n",
      "  table = driver.find_elements_by_xpath('//*[@id=\"YearTornado\"]/tbody/tr')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Month-Day</th>\n",
       "      <th>Year</th>\n",
       "      <th>F Scale</th>\n",
       "      <th>Length(in miles)</th>\n",
       "      <th>Width(in feet)</th>\n",
       "      <th>Injury</th>\n",
       "      <th>Fatality</th>\n",
       "      <th>Proparty damage</th>\n",
       "      <th>State</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Aug. 31</td>\n",
       "      <td>2021</td>\n",
       "      <td>EF0</td>\n",
       "      <td>1.71</td>\n",
       "      <td>25</td>\n",
       "      <td>0 (0)</td>\n",
       "      <td>0 (0)</td>\n",
       "      <td>$10,000</td>\n",
       "      <td>alabama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Aug. 31</td>\n",
       "      <td>2021</td>\n",
       "      <td>EF0</td>\n",
       "      <td>0.58</td>\n",
       "      <td>25</td>\n",
       "      <td>0 (0)</td>\n",
       "      <td>0 (0)</td>\n",
       "      <td></td>\n",
       "      <td>alabama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Aug. 31</td>\n",
       "      <td>2021</td>\n",
       "      <td>EF0</td>\n",
       "      <td>0.65</td>\n",
       "      <td>125</td>\n",
       "      <td>0 (0)</td>\n",
       "      <td>0 (0)</td>\n",
       "      <td>$100,000</td>\n",
       "      <td>alabama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Aug. 31</td>\n",
       "      <td>2021</td>\n",
       "      <td>EF0</td>\n",
       "      <td>0.89</td>\n",
       "      <td>20</td>\n",
       "      <td>0 (0)</td>\n",
       "      <td>0 (0)</td>\n",
       "      <td>$20,000</td>\n",
       "      <td>alabama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Aug. 30</td>\n",
       "      <td>2021</td>\n",
       "      <td>EF0</td>\n",
       "      <td>0.48</td>\n",
       "      <td>75</td>\n",
       "      <td>0 (0)</td>\n",
       "      <td>0 (0)</td>\n",
       "      <td></td>\n",
       "      <td>alabama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71923</th>\n",
       "      <td>May. 28</td>\n",
       "      <td>1953</td>\n",
       "      <td>EF2</td>\n",
       "      <td>38.2</td>\n",
       "      <td>433</td>\n",
       "      <td>0 (0)</td>\n",
       "      <td>0 (0)</td>\n",
       "      <td>$2,500</td>\n",
       "      <td>wyoming</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71924</th>\n",
       "      <td>May. 08</td>\n",
       "      <td>1952</td>\n",
       "      <td>EF1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0 (0)</td>\n",
       "      <td>0 (0)</td>\n",
       "      <td>$30</td>\n",
       "      <td>wyoming</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71925</th>\n",
       "      <td>Jun. 14</td>\n",
       "      <td>1950</td>\n",
       "      <td>EF1</td>\n",
       "      <td>.2</td>\n",
       "      <td>10</td>\n",
       "      <td>0 (0)</td>\n",
       "      <td>0 (0)</td>\n",
       "      <td>$30</td>\n",
       "      <td>wyoming</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71926</th>\n",
       "      <td>Jun. 07</td>\n",
       "      <td>1950</td>\n",
       "      <td>EF1</td>\n",
       "      <td>.2</td>\n",
       "      <td>10</td>\n",
       "      <td>0 (0)</td>\n",
       "      <td>0 (0)</td>\n",
       "      <td>$30</td>\n",
       "      <td>wyoming</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71927</th>\n",
       "      <td>May. 10</td>\n",
       "      <td>1950</td>\n",
       "      <td>EF2</td>\n",
       "      <td>2</td>\n",
       "      <td>33</td>\n",
       "      <td>0 (0)</td>\n",
       "      <td>0 (0)</td>\n",
       "      <td>$30</td>\n",
       "      <td>wyoming</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>71928 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Month-Day   Year F Scale Length(in miles) Width(in feet) Injury  \\\n",
       "0       Aug. 31  2021      EF0             1.71             25  0 (0)   \n",
       "1       Aug. 31  2021      EF0             0.58             25  0 (0)   \n",
       "2       Aug. 31  2021      EF0             0.65            125  0 (0)   \n",
       "3       Aug. 31  2021      EF0             0.89             20  0 (0)   \n",
       "4       Aug. 30  2021      EF0             0.48             75  0 (0)   \n",
       "...         ...    ...     ...              ...            ...    ...   \n",
       "71923   May. 28  1953      EF2             38.2            433  0 (0)   \n",
       "71924   May. 08  1952      EF1                2            100  0 (0)   \n",
       "71925   Jun. 14  1950      EF1               .2             10  0 (0)   \n",
       "71926   Jun. 07  1950      EF1               .2             10  0 (0)   \n",
       "71927   May. 10  1950      EF2                2             33  0 (0)   \n",
       "\n",
       "      Fatality Proparty damage    State  \n",
       "0        0 (0)         $10,000  alabama  \n",
       "1        0 (0)                  alabama  \n",
       "2        0 (0)        $100,000  alabama  \n",
       "3        0 (0)         $20,000  alabama  \n",
       "4        0 (0)                  alabama  \n",
       "...        ...             ...      ...  \n",
       "71923    0 (0)          $2,500  wyoming  \n",
       "71924    0 (0)             $30  wyoming  \n",
       "71925    0 (0)             $30  wyoming  \n",
       "71926    0 (0)             $30  wyoming  \n",
       "71927    0 (0)             $30  wyoming  \n",
       "\n",
       "[71928 rows x 9 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Day = []\n",
    "State = []\n",
    "Year = []\n",
    "FScale = []\n",
    "Length = []\n",
    "Width = []\n",
    "Injury = []\n",
    "Fatality = []\n",
    "PropartyDamage = []\n",
    "date = \"\"\n",
    "for state in States:\n",
    "    years = []\n",
    "    baseURL = f'https://data.elpasotimes.com/tornado-archive/{state}/'\n",
    "    driver.get(baseURL)\n",
    "    yearss = driver.find_elements_by_xpath('//*[@id=\"tornadoSummary\"]/tbody/tr')\n",
    "    for y in yearss:\n",
    "        years.append(y.find_element_by_xpath(\"./td[1]/a\").text)\n",
    "    years.pop(0)\n",
    "    for year in years:\n",
    "            baseURL=f'https://data.elpasotimes.com/tornado-archive/{state}/{year}/'\n",
    "            driver.get(baseURL)\n",
    "            table = driver.find_elements_by_xpath('//*[@id=\"YearTornado\"]/tbody/tr')\n",
    "            for item in table:\n",
    "                date = item.find_element_by_xpath(\"./td[1]/a\").text\n",
    "                indices = [0,7,9,14]\n",
    "                parts = [date[i:j] for i,j in zip(indices, indices[1:]+[None])]\n",
    "                Day.append(parts[0])\n",
    "                Year.append(parts[2])\n",
    "                FScale.append(item.find_element_by_xpath(\"./td[2]\").text)\n",
    "                Length.append(item.find_element_by_xpath(\"./td[3]\").text)\n",
    "                Width.append(item.find_element_by_xpath(\"./td[4]\").text)\n",
    "                Injury.append(item.find_element_by_xpath(\"./td[5]\").text)\n",
    "                Fatality.append(item.find_element_by_xpath(\"./td[6]\").text)\n",
    "                PropartyDamage.append(item.find_element_by_xpath(\"./td[7]\").text)\n",
    "                State.append(state)\n",
    "finalAllStatedDF = pd.DataFrame({\"Month-Day\":Day,\"Year\":Year,'F Scale': FScale,'Length(in miles)': Length,'Width(in feet)': Width,'Injury': Injury,'Fatality': Fatality,'Proparty damage': PropartyDamage,\"State\":State})\n",
    "driver.close()\n",
    "finalAllStatedDF.to_csv(\"finalAllStates.csv\",index=False)\n",
    "finalAllStatedDF\n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1d4f32b",
   "metadata": {},
   "source": [
    "## In the code below we start clearing the Data frame (from rows whose value is missing, and also from rows that have duplicates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2500de6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "beforeCleaningDf = pd.read_csv(\"finalAllStates.csv\")\n",
    "print(\"all the rows with there number of None values:\\n\",beforeCleaningDf.isna().sum())\n",
    "beforeCleaningDf.dropna(axis = 0, inplace=True)\n",
    "print(\"number of duplicated rows:\",beforeCleaningDf.duplicated().sum())\n",
    "beforeCleaningDf.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05b78f33",
   "metadata": {},
   "source": [
    "## In the code below we perform a deeper cleaning for each column individually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5ca1655",
   "metadata": {},
   "outputs": [],
   "source": [
    "beforeCleaningDf['Proparty damage'] = beforeCleaningDf['Proparty damage'].str.replace('$','')\n",
    "beforeCleaningDf['Proparty damage'] = beforeCleaningDf['Proparty damage'].str.replace(',','')\n",
    "beforeCleaningDf['Proparty damage'] = beforeCleaningDf['Proparty damage'].astype(np.int64)\n",
    "beforeCleaningDf.rename(columns={'Proparty damage':'Proparty damage (in $)'},inplace=True)\n",
    "\n",
    "beforeCleaningDf['F Scale'] = beforeCleaningDf['F Scale'].str.replace('EF','')\n",
    "print(\"The number of hurricanes in each strength category\\n\",beforeCleaningDf['F Scale'].value_counts())\n",
    "beforeCleaningDf.drop(beforeCleaningDf.loc[beforeCleaningDf['F Scale']=='U'].index, inplace=True)\n",
    "beforeCleaningDf['F Scale'] = beforeCleaningDf['F Scale'].astype(np.int64)\n",
    "dic = {(0,1):0,(2,3):1,(4,5):2}\n",
    "beforeCleaningDf.replace({\"F Scale\":dic},inplace=True)\n",
    "\n",
    "beforeCleaningDf['Injury'] = beforeCleaningDf['Injury'].astype(str).str.replace(r\"\\(.*\\)\",\"\")\n",
    "beforeCleaningDf['Fatality'] = beforeCleaningDf['Fatality'].astype(str).str.replace(r\"\\(.*\\)\",\"\")\n",
    "\n",
    "beforeCleaningDf['Year'] = beforeCleaningDf['Year'].astype(np.int64)\n",
    "\n",
    "beforeCleaningDf.to_csv(\"cleanAllStates.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26457695",
   "metadata": {},
   "source": [
    "## In the code below we implement the EDA (exploratory data analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1d71a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df = pd.read_csv(\"cleanAllStates.csv\")\n",
    "dic = {0:\"Moderate\",1:\"Significant\",2:\"Devestating\"}\n",
    "clean_df.replace({\"F Scale\":dic},inplace=True)\n",
    "ct1=pd.crosstab(clean_df['Year'],clean_df['F Scale'])\n",
    "ct1.plot(kind='bar',figsize=(21,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ac657de",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df = pd.read_csv(\"cleanAllStates.csv\")\n",
    "fig, axes = plt.subplots(figsize=(20,5))\n",
    "FScaleSeries = clean_df['F Scale'].value_counts()\n",
    "FScaleSeries = FScaleSeries.rename('')\n",
    "FScaleSeries.index = [\"Moderate Strength[64km/h-180km/h]\",\"Significant Strength[181km/h-331km/h]\",\"Devastating Strength[332km/h-511km/h]\"]\n",
    "FScaleSeries.plot(kind = 'pie', ax = axes,title = 'Strength of the tornado')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9648f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "groupbyDf = clean_df[['F Scale','Proparty damage (in $)']].groupby('F Scale').sum()/1000000000\n",
    "groupbyDf.index = [\"Moderate Strength\",\"Significant Strength\",\"Devastating Strength\"]\n",
    "ax = groupbyDf.plot.barh(color = 'g')\n",
    "ax.set(xlabel='Proparty damage in billion of dollars', ylabel='Strength of the tornado')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36a30e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "fscaleChange = clean_df.copy()\n",
    "order_state_by_latitude = ['hawaii','florida','louisiana','texas','mississippi','alabama'\n",
    "                          ,'georgia','south-carolina','new-mexico','arizona','arkansas','north-carolina'\n",
    "                          ,'oklahoma','tennessee','california','kentucky','virginia','missouri','kansas'\n",
    "                          ,'nevada','maryland','district-of-columbia','washington','west-virginia','colorado'\n",
    "                          ,'delaware','utah','illinois','indiana','new-jersey','ohio','new-york',\n",
    "                          'pennsylvania','nebraska','connecticut','rhode-island','iowa','massachusetts'\n",
    "                          ,'wyoming','vermont','new-hampshire','oregon','south-dakota','wisconsin','michigan'\n",
    "                          ,'maine','idaho','minnesota','montana','north-dakota']\n",
    "dic = {0:\"Moderate Damage\",1:\"Significant Damage\",2:\"Devastating Damage\"}\n",
    "fscaleChange.replace({\"F Scale\":dic},inplace=True)\n",
    "ct = pd.crosstab(fscaleChange['State'],fscaleChange['F Scale'])\n",
    "font = {'weight' : 'bold',\n",
    "        'size'   : 15}\n",
    "plt.rc('font', **font)\n",
    "ax = ct.loc[order_state_by_latitude].plot(kind = 'bar',figsize = (20,7))\n",
    "ax.set(ylabel='number of the tornadoes')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0eb3c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "groupbyDf = clean_df[['State','Injury','Fatality']].groupby('State').sum()\n",
    "groupbyDf['Injury+Fatality'] = groupbyDf.iloc[:,-2:].sum(axis = 1)\n",
    "groupbyDf = groupbyDf.reset_index()\n",
    "bins = [-1,1000,3000,5000,8616]\n",
    "labels = [\"0-1000\",'1001-3000','3001-5000','5001-8616']\n",
    "groupbyDf['Injury+Fatality-Number'] = pd.cut(groupbyDf['Injury+Fatality'], bins = bins,labels=labels)\n",
    "ct = pd.crosstab(groupbyDf['State'],groupbyDf['Injury+Fatality-Number'])\n",
    "ax = ct.loc[order_state_by_latitude].plot(kind = 'bar',figsize = (20,10))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f983fdf7",
   "metadata": {},
   "source": [
    "## Machine learning (part one) - can the intensity of the tornado be predicted?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "200db856",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(file_name, target_column):\n",
    "    df = pd.read_csv(file_name)\n",
    "    X = df.drop(target_column, axis = 1)\n",
    "    y = pd.Series(df[target_column])\n",
    "\n",
    "    return X, y\n",
    "\n",
    "\n",
    "def split_to_train_and_test(X, y, test_ratio, rand_state):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_ratio, random_state=rand_state)\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "\n",
    "def scale_features(X_train, scale_type):\n",
    "    if scale_type == 'standard':\n",
    "        scaler = StandardScaler()\n",
    "        X_train_scaled = scaler.fit_transform(X_train)\n",
    "    elif scale_type == 'minmax':\n",
    "        scaler = MinMaxScaler()\n",
    "        X_train_scaled = scaler.fit_transform(X_train)\n",
    "    \n",
    "    return scaler, X_train_scaled\n",
    "\n",
    "\n",
    "\n",
    "def scale_test_features(X_test, scaler):\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    return X_test_scaled\n",
    "    \n",
    "\n",
    "    \n",
    "def train_model(X_train, y_train):\n",
    "    clf_model = LogisticRegression()\n",
    "    trained_model = clf_model.fit(X_train, y_train)\n",
    "    return trained_model\n",
    "\n",
    "\n",
    "def predict_model(trained_model, X_test):\n",
    "    predicted_vals = trained_model.predict(X_test)\n",
    "    return predicted_vals\n",
    "\n",
    "\n",
    "def evaluate_performance(y_test,y_predicted):\n",
    "    evaluate_value = metrics.f1_score(y_test, y_predicted, average='micro')\n",
    "    return evaluate_value\n",
    "\n",
    "X, y = load_dataset(\"c:/users/oren keinan/cleanAllStates.csv\", \"F Scale\")\n",
    "\n",
    "\n",
    "X=X.drop({\"Month-Day\",\"Year\",\"State\"},axis=1)\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = split_to_train_and_test(X,y,0.3,41)\n",
    "\n",
    "standard_scaler, X_train_standard_scaled = scale_features(X_train,\"standard\")\n",
    "\n",
    "X_test_scaled = scale_test_features(X_test, standard_scaler)\n",
    "\n",
    "trained_standard_model = train_model(X_train_standard_scaled, y_train)\n",
    "\n",
    "predict_vals = predict_model(trained_standard_model ,X_test_scaled)\n",
    "\n",
    "y_pred = pd.Series(predict_vals,index=X_test.index)\n",
    "\n",
    "eva = evaluate_performance(y_test,y_pred)\n",
    "\n",
    "print(metrics.confusion_matrix(y_test, y_pred))\n",
    "\n",
    "print(\"accuracy is:\",metrics.accuracy_score(y_test, y_pred))\n",
    "print(\"precision is:\",metrics.precision_score(y_test, y_pred, average='micro'))\n",
    "print(\"recall is:\",metrics.recall_score(y_test, y_pred, average='micro'))\n",
    "print(\"f1 is:\",metrics.f1_score(y_test, y_pred, average='micro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79f54c4f",
   "metadata": {},
   "source": [
    "## Machine learning (part two) - Is it possible by entering the distance and width values to predict the intensity of the tornado? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ec26a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('cleanAllStates.csv')\n",
    "df_FScale_0 = df[df['F Scale']==0].reset_index(drop=True)\n",
    "df_FScale_1 = df[df['F Scale']==1].reset_index(drop=True)\n",
    "df_FScale_2 = df[df['F Scale']==2].reset_index(drop=True)\n",
    "df_FScale_0['TornadoLvl'] = 0\n",
    "df_FScale_1['TornadoLvl'] = 1\n",
    "df_FScale_2['TornadoLvl'] = 2\n",
    "df = pd.concat([df_FScale_0, df_FScale_1,df_FScale_2], ignore_index=True).drop(['F Scale'], axis=1)\n",
    "\n",
    "X = df[df.columns[(df.columns != 'Month-Day') & (df.columns != 'Year') & (df.columns != 'TornadoLvl') &\n",
    "                 (df.columns != 'Proparty damage (in $)') & (df.columns != 'State') & \n",
    "                 (df.columns != 'Injury') & (df.columns != 'Fatality')]]\n",
    "\n",
    "y = df['TornadoLvl']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=40)\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(-2,2))\n",
    "\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "model = LogisticRegression().fit(X_train_scaled, y_train)\n",
    "\n",
    "scaler.fit(X_test)\n",
    "Length = float(input(\"Please enter Length(in miles) of the tornado (between 0-500): \"))\n",
    "Width = float(input('Please Width(in feet) of the tornado (between 0-4576): '))\n",
    "LenWid = scaler.transform([[Length,Width]])\n",
    "predicted_vals = model.predict_proba(LenWid)[0]\n",
    "while(0<=Length<=500 and 0<=Width<=4575):\n",
    "    lowIntensity, medIntensity, highIntensity = predicted_vals[0]*100, predicted_vals[1]*100, predicted_vals[2]*100\n",
    "    print('Length , Width: ({},{}): Low tornado intensity probability: {:.2f}%\\n\\t\\t\\tMedium tornado intensity probability: {:.2f}%\\n\\t\\t\\tHigh tornado intensity probability: {:.2f}%\\n'.format(Length,Width, lowIntensity,medIntensity, highIntensity))\n",
    "    Length = float(input(\"Please enter Length(in miles) of the tornado (between 0-500): \"))\n",
    "    Width = float(input('Please enter  Width(in feet) of the tornado (between 0-4576):'))\n",
    "    print('\\n')\n",
    "    LenWid = scaler.transform([[Length,Width]])\n",
    "    predicted_vals = model.predict_proba(LenWid)[0]\n",
    "print('Input is out of range!')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
